{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06b85aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15624b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df = pd.read_csv('Housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb2d2289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>509 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900  1.0  296   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671  2.0  242   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671  2.0  242   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622  3.0  222   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622  3.0  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "504  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786  1.0  273   \n",
       "505  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875  1.0  273   \n",
       "506  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675  1.0  273   \n",
       "507  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889  1.0  273   \n",
       "508  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050  1.0  273   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "504     21.0  391.99   9.67  22.4  \n",
       "505     21.0  396.90   9.08  20.6  \n",
       "506     21.0  396.90   5.64  23.9  \n",
       "507     21.0  393.45   6.48  22.0  \n",
       "508     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[509 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf54c033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      3\n",
       "CHAS       0\n",
       "NOX        2\n",
       "RM         0\n",
       "AGE        1\n",
       "DIS        0\n",
       "RAD        1\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      1\n",
       "MEDV       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f709a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = boston_df.fillna(boston_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "792a402d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "MEDV       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2e8cca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41c416ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate values in the dataset after removal.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900  1.0  296   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671  2.0  242   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671  2.0  242   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622  3.0  222   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622  3.0  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "504  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786  1.0  273   \n",
       "505  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875  1.0  273   \n",
       "506  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675  1.0  273   \n",
       "507  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889  1.0  273   \n",
       "508  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050  1.0  273   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "504     21.0  391.99   9.67  22.4  \n",
       "505     21.0  396.90   9.08  20.6  \n",
       "506     21.0  396.90   5.64  23.9  \n",
       "507     21.0  393.45   6.48  22.0  \n",
       "508     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[505 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "if len(data) == len(data):\n",
    "    print(\"No duplicate values in the dataset after removal.\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3896580a",
   "metadata": {},
   "source": [
    "# Input Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9a2c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['MEDV', 'RAD'], axis=1)\n",
    "y = data['MEDV']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa7ccce",
   "metadata": {},
   "source": [
    "# MODEL TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de6689c",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1e862c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Report\n",
      "MSE: 21.161004783707845\n",
      "CV Score: 35.64681041086956\n",
      "R^2 Score: 0.6308893114335621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Model Coefficients'}>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def train(model, X, y):\n",
    "    # train the model\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # predict the training set\n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    # perform cross-validation\n",
    "    cv_score = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=5)\n",
    "    cv_score = np.abs(np.mean(cv_score))\n",
    "    \n",
    "    # Calculate R-squared score\n",
    "    r2 = r2_score(y_test, pred)\n",
    "    \n",
    "    print(\"Model Report\")\n",
    "    print(\"MSE:\", mean_squared_error(y_test, pred))\n",
    "    print('CV Score:', cv_score)\n",
    "    print('R^2 Score:', r2)\n",
    "\n",
    "# Assuming X and y are your features and target variables respectively\n",
    "# Assuming X is a DataFrame\n",
    "# Assuming y is a Series\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "train(model, X_scaled, y)\n",
    "\n",
    "# Get coefficients\n",
    "coef = pd.Series(model.coef_, index=X.columns).sort_values()\n",
    "coef.plot(kind='bar', title='Model Coefficients')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77e2108a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Report\n",
      "MSE: 31.365354330708662\n",
      "CV Score: 44.36976237623763\n",
      "R^2 Score: 0.4528951884623317\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def train(model, X, y):\n",
    "    # train the model\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # predict the training set\n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    # perform cross-validation\n",
    "    cv_score = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=5)\n",
    "    cv_score = np.abs(np.mean(cv_score))\n",
    "    \n",
    "    # Calculate R-squared score\n",
    "    r2 = r2_score(y_test, pred)\n",
    "    \n",
    "    print(\"Model Report\")\n",
    "    print(\"MSE:\", mean_squared_error(y_test, pred))\n",
    "    print('CV Score:', cv_score)\n",
    "    print('R^2 Score:', r2)\n",
    "\n",
    "# Assuming X and y are your features and target variables respectively\n",
    "# Assuming X is a DataFrame\n",
    "# Assuming y is a Series\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create the model\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "train(model, X_scaled, y)\n",
    "\n",
    "# Decision Trees don't have coefficients like linear models,\n",
    "# so we won't plot coefficients here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1459186f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Report\n",
      "MSE: 16.41948392125984\n",
      "CV Score: 21.860576116831673\n",
      "R^2 Score: 0.7135954989836815\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def train(model, X, y):\n",
    "    # train the model\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # predict the training set\n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    # perform cross-validation\n",
    "    cv_score = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=5)\n",
    "    cv_score = np.abs(np.mean(cv_score))\n",
    "    \n",
    "    # Calculate R-squared score\n",
    "    r2 = r2_score(y_test, pred)\n",
    "    \n",
    "    print(\"Model Report\")\n",
    "    print(\"MSE:\", mean_squared_error(y_test, pred))\n",
    "    print('CV Score:', cv_score)\n",
    "    print('R^2 Score:', r2)\n",
    "\n",
    "# Assuming X and y are your features and target variables respectively\n",
    "# Assuming X is a DataFrame\n",
    "# Assuming y is a Series\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "train(model, X_scaled, y)\n",
    "\n",
    "# Random Forest doesn't have coefficients like linear models,\n",
    "# so we won't plot coefficients here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61fc85f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Report\n",
      "MSE: 11.515684535433069\n",
      "CV Score: 18.99824106336633\n",
      "R^2 Score: 0.7991323053118844\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def train(model, X, y):\n",
    "    # train the model\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # predict the training set\n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    # perform cross-validation\n",
    "    cv_score = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=5)\n",
    "    cv_score = np.abs(np.mean(cv_score))\n",
    "    \n",
    "    # Calculate R-squared score\n",
    "    r2 = r2_score(y_test, pred)\n",
    "    \n",
    "    print(\"Model Report\")\n",
    "    print(\"MSE:\", mean_squared_error(y_test, pred))\n",
    "    print('CV Score:', cv_score)\n",
    "    print('R^2 Score:', r2)\n",
    "\n",
    "# Assuming X and y are your features and target variables respectively\n",
    "# Assuming X is a DataFrame\n",
    "# Assuming y is a Series\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create the model\n",
    "model = ExtraTreesRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "train(model, X_scaled, y)\n",
    "\n",
    "# Extra Trees doesn't have coefficients like linear models,\n",
    "# so we won't plot coefficients here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c95ed44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Report\n",
      "MSE: 13.950304753752249\n",
      "CV Score: 18.464064268348928\n",
      "R^2 Score: 0.7566653074369327\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def train(model, X, y):\n",
    "    # train the model\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # predict the training set\n",
    "    pred = model.predict(x_test)\n",
    "    \n",
    "    # perform cross-validation\n",
    "    cv_score = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=5)\n",
    "    cv_score = np.abs(np.mean(cv_score))\n",
    "    \n",
    "    # Calculate R-squared score\n",
    "    r2 = r2_score(y_test, pred)\n",
    "    \n",
    "    print(\"Model Report\")\n",
    "    print(\"MSE:\", mean_squared_error(y_test, pred))\n",
    "    print('CV Score:', cv_score)\n",
    "    print('R^2 Score:', r2)\n",
    "\n",
    "# Assuming X and y are your features and target variables respectively\n",
    "# Assuming X is a DataFrame\n",
    "# Assuming y is a Series\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Create the model\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "train(model, X_scaled, y)\n",
    "\n",
    "# There's no direct 'coef_' attribute for GradientBoostingRegressor\n",
    "# as it's not a linear model, so we won't plot coefficients here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab050477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
